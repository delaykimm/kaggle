{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IG7Ni0gzNJNh"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.losses import MeanSquaredLogarithmicError\n",
        "from tensorflow.keras.losses import MeanSquaredError,BinaryCrossentropy,MeanAbsoluteError\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = './train.csv'\n",
        "file_path2 = './test.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv(file_path)\n",
        "df.index = df[\"id\"]\n",
        "df = pd.DataFrame(df.iloc[:, 1:])\n",
        "df2 = pd.read_csv(file_path2)\n",
        "df2.index = df2[\"id\"]\n",
        "df2 = pd.DataFrame(df2.iloc[:,1:])\n",
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1]\n",
        "X_test = df2\n",
        "\n",
        "# Split the data into training and validating sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,y, test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "oCKi4OguNapN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, BatchNormalization, Dense\n",
        "#from tensorflow.keras.initializers import VarianceScaling\n",
        "from tensorflow.keras.initializers import GlorotUniform\n",
        "\n",
        "class RegressionModel(tf.keras.Model):\n",
        "    def __init__(self, input_size):\n",
        "        super(RegressionModel, self).__init__()\n",
        "\n",
        "        # Fully connected layers with Xavier initialization\n",
        "        self.fc1 = layers.Dense(16, input_shape=(input_size,), kernel_initializer='glorot_uniform')\n",
        "        self.batch_norm1 = layers.BatchNormalization(epsilon=1e-5)\n",
        "        self.relu1 = layers.Activation('relu')\n",
        "\n",
        "        self.fc2 = layers.Dense(32, kernel_initializer='glorot_uniform')\n",
        "        self.batch_norm2 = layers.BatchNormalization(epsilon=1e-5)\n",
        "        self.gelu = layers.Activation('gelu')\n",
        "\n",
        "        self.fc3 = layers.Dense(64, kernel_initializer='glorot_uniform')\n",
        "        self.batch_norm3 = layers.BatchNormalization(epsilon=1e-5)\n",
        "        self.relu2 = layers.Activation('relu')\n",
        "\n",
        "        self.fc4 = layers.Dense(1, kernel_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, x):\n",
        "        # Fully connected layers with batch normalization and activation functions\n",
        "        x = self.relu1(self.batch_norm1(self.fc1(x)))\n",
        "        x = self.gelu(self.batch_norm2(self.fc2(x)))\n",
        "        x = self.relu2(self.batch_norm3(self.fc3(x)))\n",
        "\n",
        "        # Output layer\n",
        "        x = self.fc4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Example usage:\n",
        "input_size = 11\n",
        "model = RegressionModel(input_size)\n",
        "\n",
        "# Optionally, you can build the model to show the summary\n",
        "model.build((None, input_size))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "fcEcSLlfO_YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(y_true, y_pred):\n",
        "    return tfp.stats.percentile(tf.abs(y_true - y_pred), q=50)\n",
        "\n",
        "def metric_fn(y_true, y_pred):\n",
        "    return tfp.stats.percentile(tf.abs(y_true - y_pred), q=100) - tfp.stats.percentile(tf.abs(y_true - y_pred), q=0)\n",
        "\n",
        "callbacks_list = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        patience=30,\n",
        "        restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=3, min_lr=0.00001),\n",
        "]"
      ],
      "metadata": {
        "id": "huaB0H2zPESj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.013, beta_1=0.5), loss=loss_fn, metrics=metric_fn)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.013, beta_1=0.5), loss=loss_fn, metrics=metric_fn)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train.astype('float32'),\n",
        "    y_train.astype('float32'),\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks_list,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "QbpBcRrFPKp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test.astype('float32'))\n",
        "df_prediction = pd.DataFrame(y_pred)\n",
        "df_prediction"
      ],
      "metadata": {
        "id": "E_ho5BqLPQzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "df_prediction[0].plot(kind='hist', bins=20, title=0)\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "rhxKKTwooHH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test= pd.read_csv('./sample_submission.csv')\n",
        "test['Hardness'] = df_prediction\n",
        "test.to_csv('submission.csv',index=False)"
      ],
      "metadata": {
        "id": "NNqFBsFtTpHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,4))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.title('Training and validation losses')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(history.history['metric_fn'], label='Training accuracy')\n",
        "plt.plot(history.history['val_metric_fn'], label='Validation accuracy')\n",
        "plt.title('Training and validation accuracies')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "Icdn6rH8n6BP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights, biases = model.layers[0].get_weights()\n",
        "\n",
        "# Print or use the final weights as needed\n",
        "print(\"가중치:\", weights)\n",
        "print(\"편향:\", biases)"
      ],
      "metadata": {
        "id": "pl3Biftp1yJ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}